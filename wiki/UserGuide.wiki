[UserGuide#What_is_olap4cloud What is olap4cloud?]

[UserGuide#How_to_build How to build]

 * [UserGuide#Prerequisites Prerequisites] 

 * [UserGuide#Getting_the_code Getting the code]

 * [UserGuide#Build_the_code Build the code]

[UserGuide#Installing Installing]

 * [UserGuide#Prerequisites Prerequisites]

=What is olap4cloud=

olap4cloud is Hadoop & HBase based OLAP engine. It constructed to serve the OLAP-like queries containing grouping and aggregations.

The typical query which can be served by olap4cloud looks like following: 

select d3, sum(m1), min(m2) from facts where d1 in (1,2) and d2 in (2,3) group by d3;

The main features of olap4cloud which allows to outperform the brute-force map/reduce competitors(Hive, Pig) are:
 * data defragmentation - olap4cloud stores data in the order where rows with the same dimensions will be stored closely. 
 * intensive indexing - olap4cloud constructs special indexes. These indexes helps to locate where data stored and avoid full scan during query execution.
 * preaggregations - olap4cloud uses classic lattice model to construct aggregation cuboids. It allows to achieve lower latency on queries where aggregations are already calculated.

=How to build=

At this time the olap4cloud project is in the highly experimental stage. So we don't have any stable builds yet, and recommended way to get the jar file is to get the fresh source code from SVN and build it.

==Prerequisites==

You need to have installed svn client, jdk 6 and ant on your computer in order to build the olap4cloud.

==Getting the code==

Obtain the code by using the one of SVN checkout commands listed on Source tab (you will need an SVN client installed on your computer).

==Build the code==

olap4cloud can be built by simply running the "ant" command in the root directory of the project. 
After build is done you will see the olap4cloud.jar file in the root directory of the project.

Other helpful ant targets are:
- clean - remove all compiled java classes and jars.
- test.build - build tests
- test.generate_test_data - generate test data for tests. Data files will be located under test/data directory. 

=Installing=

==Prerequisites==

You need to have Hadoop and HBase up and running on your cluster. 

Additionally olap4cloud intensively uses Hadoop & HBase Map/Reduce facility, so you need to have Hadoop and HBase configured to be able run Map/Reduce jobs against HBase tables. 
This part can be done using instructions available on the following address: http://hadoop.apache.org/hbase/docs/current/api/org/apache/hadoop/hbase/mapreduce/package-summary.html#classpath